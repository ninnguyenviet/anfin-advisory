# import pandas as pd
# import json
# from google.cloud import bigquery
# from google.oauth2 import service_account

# import streamlit as st


# def load_account_requests():
#     # L·∫•y credentials t·ª´ streamlit secrets
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)

#     query = """
#        SELECT * 
#        FROM `anfinx-prod.anfinx_advisory.commodity_advisory_account_request_dashboard_vw`
#     """
#     df_raw = client.query(query).to_dataframe()

#     # Expand JSON t·ª´ c·ªôt "data"
#     expanded = df_raw["data"].apply(lambda x: json.loads(x) if pd.notna(x) else {})
#     expanded_df = pd.json_normalize(expanded)
#     expanded_df.columns = [col.replace(".", "_") for col in expanded_df.columns]

#     # Ch·ªâ l·∫•y c√°c field c·∫ßn
#     need_cols = ["avatar_url", "bio", "display_name", "group_name", "highlights","service_info", "phone_number"]
#     expanded_df = expanded_df.reindex(columns=need_cols, fill_value=pd.NA)

#     # K·∫øt h·ª£p l·∫°i
#     df = pd.concat([df_raw.drop(columns=["data"]), expanded_df], axis=1)

#     # ƒê·∫£m b·∫£o kh√¥ng c√≥ c·ªôt tr√πng
#     df = df.loc[:, ~df.columns.duplicated()]

#     # Reset index & sort
#     df = df.reset_index(drop=True)
#     if "created_at" in df.columns:
#         df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce")
#         df = df.sort_values(by="created_at", ascending=False, na_position="last")

#     return df
# # -------------------------------------------------
# def load_seasons_from_bq():
    
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )

#     # Kh·ªüi t·∫°o BigQuery client
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)
#     query = """
#          SELECT 
#             id, 
#             CONCAT(
#                 FORMAT_DATE('%m/%Y', DATE(end_date)),
#                 " Cu·ªôc thi vinh danh c√°c broker xu·∫•t s·∫Øc nh·∫•t"
#             ) AS name, 
#             start_date, 
#             end_date
#         FROM `anfin-prod.raw_mysql.commodity_advisory_advisory_leaderboard_season`
#         where id != "season_1_id"
#     """
#     df = client.query(query).to_dataframe()
#     return df

# def load_kpi_data():
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )

#     # Kh·ªüi t·∫°o BigQuery client
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)

#     query = """
#          SELECT * FROM `anfinx-prod.anfinx_advisory.anfinx_advisory_overview_dashboard_vw` 
#     """

#     df = client.query(query).to_dataframe()
#     return df


# def load_season_data_new(season_id):
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)

#     query = """
#         SELECT user_id,tkcv, leaderboard_id, full_name,registered_tnc_at, lot,lot_standard, transaction_fee,gross_pnl, net_pnl, total_lot_standard, rank, hidden_mode_activated_at, mode, alias_name    FROM `anfinx-prod.anfinx_advisory.anfinx_advisory_user_rank_by_data_vw` 
#         WHERE leaderboard_id in ( @season_id)
#     """

#     job_config = bigquery.QueryJobConfig(
#         query_parameters=[
#             bigquery.ScalarQueryParameter("season_id", "STRING", season_id)
#         ]
#     )

#     df = client.query(query, job_config=job_config).to_dataframe()
#     return df


# def load_all_kpi_view(month) -> pd.DataFrame:
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)

#     query = """
#         SELECT * FROM `anfinx-prod.anfinx_advisory.anfinx_advisory_all_kpi_data_vw`
#         WHERE month in ( @month)
#     """

#     job_config = bigquery.QueryJobConfig(
#         query_parameters=[
#             bigquery.ScalarQueryParameter("month", "Date", month)
#         ]
#     )
#     df = client.query(query).to_dataframe()
#     return df




# VIEW_FQN = "anfinx-prod.anfinx_advisory.anfinx_advisory_all_kpi_data_vw"

# def _bq_client():
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )
#     return bigquery.Client(credentials=credentials, project=credentials.project_id)

# def load_advisory_dims():
#     """
#     L·∫•y danh s√°ch month, type (nh·∫π) ƒë·ªÉ build filter & nh·∫≠n di·ªán ki·ªÉu d·ªØ li·ªáu c·ªßa month.
#     """
#     client = _bq_client()
#     q = f"SELECT DISTINCT month, type FROM `anfinx-prod.anfinx_advisory.anfinx_advisory_all_kpi_data_vw`"
#     return client.query(q).to_dataframe()

# def load_advisory_commission_data(months=None, types=None, month_is_date: bool | None = None) -> pd.DataFrame:
#     """
#     T·∫£i d·ªØ li·ªáu ch√≠nh theo b·ªô l·ªçc.
#     - months: list[date] n·∫øu month_is_date=True, ng∆∞·ª£c l·∫°i list[str]
#     - types:  list[str]
#     - month_is_date: None -> b·ªè WHERE month (load all); True/False -> filter theo ƒë√∫ng ki·ªÉu
#     """
#     client = _bq_client()

#     where = []
#     params = []

#     if month_is_date is not None and months:
#         where.append("month IN UNNEST(@months)")
#         if month_is_date:
#             params.append(bigquery.ArrayQueryParameter("months", "DATE", months))
#         else:
#             params.append(bigquery.ArrayQueryParameter("months", "STRING", months))

#     if types:
#         where.append("type IN UNNEST(@types)")
#         params.append(bigquery.ArrayQueryParameter("types", "STRING", types))

#     where_sql = ("WHERE " + " AND ".join(where)) if where else ""
#     q = f"SELECT * FROM `{VIEW_FQN}` {where_sql}"

#     job_config = bigquery.QueryJobConfig(query_parameters=params or None)
#     return client.query(q, job_config=job_config).to_dataframe()

# def load_latest_update_times() -> pd.DataFrame:
#      # L·∫•y credentials t·ª´ streamlit secrets
#     credentials = service_account.Credentials.from_service_account_info(
#         st.secrets["google_service_account"]
#     )
#     client = bigquery.Client(credentials=credentials, project=credentials.project_id)
#     """
#     Tr·∫£ v·ªÅ 1 d√≤ng, 2 c·ªôt:
#       - order_last_update: MAX(created_at) c·ªßa anfin-prod.commodity.order (UTC+7)
#       - pnl_last_update  : MAX(created_at) c·ªßa anfin-prod.commodity.pnl_close_status (UTC+7)
#     """
#     sql = """
#     WITH order_max AS (
#       SELECT MAX(DATE_ADD(CAST(created_at AS TIMESTAMP), INTERVAL 7 HOUR)) AS max_ts
#       FROM `anfin-prod.commodity.order`
#     ),
#     pnl_max AS (
#       SELECT MAX(DATE_ADD(CAST(created_at AS TIMESTAMP), INTERVAL 7 HOUR)) AS max_ts
#       FROM `anfin-prod.commodity.pnl_close_status`
#     )
#     SELECT
#       (SELECT max_ts FROM order_max) AS order_last_update,
#       (SELECT max_ts FROM pnl_max)  AS pnl_last_update
#     """
#     return client.query(sql).to_dataframe()

import streamlit as st
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo  # Python 3.9+
from services.bigquery_client import load_seasons_from_bq, load_season_data_new, load_latest_update_times  # <= TH√äM IMPORT

# =========================
# Page setup
# =========================
st.set_page_config(
    page_title="Advisory User Rank",
    page_icon="üèÜ",
    layout="wide"
)
st.markdown("# üèÜ Advisory User Rank Dashboard")

# =========================
# Helpers
# =========================
def format_money(val):
    if pd.isna(val):
        return "-"
    try:
        val = float(val)
    except Exception:
        return "-"
    a = abs(val)
    if a >= 1e9:
        return f"{val / 1e9:,.2f} t·ª∑"
    if a >= 1e6:
        return f"{val / 1e6:,.1f} tri·ªáu"
    if a >= 1e3:
        return f"{val / 1e3:,.0f} ngh√¨n"
    return f"{val:,.0f}"

def safe_float(x, default=0.0):
    try:
        return float(x)
    except Exception:
        return float(default)

def is_eligible(rec: dict) -> bool:
    has_tnc = pd.notnull(rec.get("registered_tnc_at"))
    mode_public = rec.get("mode") == "PUBLIC"
    net_pnl_pos = pd.notnull(rec.get("net_pnl")) and safe_float(rec.get("net_pnl")) > 0
    return bool(has_tnc and mode_public and net_pnl_pos)

def ineligible_reason(rec: dict) -> str | None:
    if pd.isnull(rec.get("registered_tnc_at")):
        return "Ch∆∞a TnC"
    if rec.get("mode") == "PRIVATE":
        return "ƒêang b·∫≠t ·∫©n danh"
    if pd.isnull(rec.get("net_pnl")) or safe_float(rec.get("net_pnl")) <= 0:
        return "Kh√°ch b·ªã l·ªó"
    return None

def month_pool_from_df(df_month: pd.DataFrame) -> int:
    if df_month.empty:
        return 0
    total_lot_month = df_month["total_lot_standard"].max()
    total_lot_month = 0 if pd.isna(total_lot_month) else total_lot_month
    return round(total_lot_month * 10_000)

# Quy t·∫Øc chia th∆∞·ªüng TOP1/2/3
reward_split = [0.5, 0.3, 0.2]

# =========================
# Load seasons
# =========================
seasons_df = load_seasons_from_bq()
if seasons_df.empty:
    st.warning("Kh√¥ng t√¨m th·∫•y season n√†o t·ª´ BigQuery.")
    st.stop()

seasons_df["start_date"] = pd.to_datetime(seasons_df["start_date"])
seasons_df["end_date"] = pd.to_datetime(seasons_df["end_date"])
seasons_df = seasons_df.sort_values(by=["start_date", "id"]).reset_index(drop=True)

season_name_options = seasons_df["name"].tolist()
season_name_to_id = dict(zip(seasons_df["name"], seasons_df["id"]))

now_local = datetime.now(ZoneInfo("Asia/Ho_Chi_Minh"))  # <= d√πng VN time cho "Dashboard c·∫≠p nh·∫≠t l√∫c"
default_idx_candidates = seasons_df[
    (seasons_df["start_date"].dt.month == now_local.month) &
    (seasons_df["start_date"].dt.year == now_local.year)
].index.tolist()
default_index = default_idx_candidates[0] if default_idx_candidates else 0

selected_season_name = st.selectbox("Ch·ªçn Season:", options=season_name_options, index=default_index)
selected_season_id = season_name_to_id[selected_season_name]

# =========================
# L·∫•y m·ªëc th·ªùi gian c·∫≠p nh·∫≠t 2 ngu·ªìn & t√≠nh "data update ƒë·∫øn"
# =========================
with st.spinner("ƒêang ki·ªÉm tra m·ªëc c·∫≠p nh·∫≠t d·ªØ li·ªáu..."):
    _df_updates = load_latest_update_times()
    if _df_updates.empty or _df_updates.isna().all(axis=None):
        order_last_update = None
        pnl_last_update = None
    else:
        order_last_update = pd.to_datetime(_df_updates.loc[0, "order_last_update"]) if "order_last_update" in _df_updates.columns else None
        pnl_last_update   = pd.to_datetime(_df_updates.loc[0, "pnl_last_update"]) if "pnl_last_update" in _df_updates.columns else None

    # ‚ÄúData update ƒë·∫øn‚Äù = MIN(order_last_update, pnl_last_update) (b·∫£o th·ªß)
    candidates = [ts for ts in [order_last_update, pnl_last_update] if pd.notnull(ts)]
    data_update_to = min(candidates) if candidates else None

# =========================
# Main data
# =========================
with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu season..."):
    df_current = load_season_data_new([selected_season_id])
    if df_current.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho season ƒë∆∞·ª£c ch·ªçn.")
        st.stop()
    df_current.sort_values(by=["leaderboard_id", "rank"], inplace=True)

selected_idx_list = seasons_df.index[seasons_df["id"] == selected_season_id].tolist()
selected_idx = selected_idx_list[0] if selected_idx_list else 0

# =========================
# 1) C·ªông d·ªìn CH∆ØA CHI c√°c TH√ÅNG TR∆Ø·ªöC (t√≠nh tr√™n POOL S·∫¥N C√ì t·ª´ng th√°ng)
# =========================
carryover_rows = []
cumulative_unpaid_before = 0  # c·ªông d·ªìn CH∆ØA CHI ƒë·∫øn cu·ªëi TH√ÅNG TR∆Ø·ªöC (rolling)

if selected_idx > 0:
    for i in range(0, selected_idx):
        prev_row = seasons_df.iloc[i]
        prev_id = prev_row["id"]
        prev_name = prev_row["name"]

        df_prev = load_season_data_new([prev_id])
        if df_prev.empty:
            carryover_rows.append({
                "Season": prev_name,
                "Pool th√°ng (VNƒê)": 0,
                "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG TR∆Ø·ªöC (VNƒê)": cumulative_unpaid_before,
                "Pool s·∫µn c√≥ trong TH√ÅNG (VNƒê)": cumulative_unpaid_before,
                "ƒê√£ chi tr·∫£ trong TH√ÅNG (VNƒê)": 0,
                "Ti·ªÅn ch∆∞a chi tr·∫£ trong TH√ÅNG (VNƒê)": cumulative_unpaid_before,
                "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG (VNƒê)": cumulative_unpaid_before
            })
            continue

        pool_prev = month_pool_from_df(df_prev)
        df_prev_top3 = df_prev.sort_values(by="lot_standard", ascending=False).head(3).reset_index(drop=True)

        available_before_this_month = cumulative_unpaid_before
        available_pool_this_month = pool_prev + available_before_this_month

        used_ratio = 0.0
        paid_this_month = 0
        unpaid_this_month = 0

        for slot, row_prev in enumerate(df_prev_top3.itertuples()):
            if slot >= len(reward_split):
                break
            ratio = reward_split[slot]
            used_ratio += ratio
            rprev = row_prev._asdict()
            portion = round(available_pool_this_month * ratio)
            if is_eligible(rprev):
                paid_this_month += portion
            else:
                unpaid_this_month += portion

        missing_ratio = max(0.0, 1.0 - used_ratio)
        if missing_ratio > 1e-9:
            unpaid_this_month += round(available_pool_this_month * missing_ratio)

        cumulative_unpaid_before = unpaid_this_month

        carryover_rows.append({
            "Season": prev_name,
            "Pool th√°ng (VNƒê)": pool_prev,
            "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG TR∆Ø·ªöC (VNƒê)": available_before_this_month,
            "Pool s·∫µn c√≥ trong TH√ÅNG (VNƒê)": available_pool_this_month,
            "ƒê√£ chi tr·∫£ trong TH√ÅNG (VNƒê)": paid_this_month,
            "Ti·ªÅn ch∆∞a chi tr·∫£ trong TH√ÅNG (VNƒê)": unpaid_this_month,
            "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG (VNƒê)": cumulative_unpaid_before
        })

# =========================
# 2) Th√°ng ƒëang ch·ªçn: Pool hi·ªán t·∫°i & Pool S·∫¥N C√ì (ƒë√∫ng c√¥ng th·ª©c)
# =========================
current_pool = month_pool_from_df(df_current)
available_pool_upto_current = current_pool + cumulative_unpaid_before  # ‚úÖ

# =========================
# 3) Ph√¢n b·ªï th√°ng hi·ªán t·∫°i
# =========================
df_top3_current = df_current.sort_values(by="lot_standard", ascending=False).head(3).reset_index(drop=True)
bonus_given_from_available = 0
unpaid_in_current_month = 0
bonuses_rows = []
used_ratio_current = 0.0

for slot, row in enumerate(df_top3_current.itertuples()):
    if slot >= len(reward_split):
        break
    r = row._asdict()
    rank = slot + 1
    ratio = reward_split[slot]
    used_ratio_current += ratio

    amount_this_slot = round(available_pool_upto_current * ratio)
    eligible = is_eligible(r)
    status = "ƒê∆∞·ª£c nh·∫≠n" if eligible else "C·ªông d·ªìn th√°ng sau"
    reason = None if eligible else ineligible_reason(r)

    if eligible:
        bonus_given_from_available += amount_this_slot
    else:
        unpaid_in_current_month += amount_this_slot

    medals = {1: "ü•á", 2: "ü•à", 3: "ü•â"}
    bonuses_rows.append({
        "H·∫°ng": f"{medals.get(rank, '')} TOP {rank}",
        "User ID": r.get("user_id"),
        "H·ªç t√™n": r.get("full_name"),
        "T√™n gi·∫£i th∆∞·ªüng": "Chi·∫øn Th·∫ßn Lot",
        "T·ªïng Lot": r.get("lot_standard"),
        "Ti·ªÅn th∆∞·ªüng (VNƒê)": f"{amount_this_slot:,.0f}",
        "ƒêi·ªÅu ki·ªán nh·∫≠n th∆∞·ªüng": status,
        "L√Ω do": reason
    })

missing_ratio_current = max(0.0, 1.0 - used_ratio_current)
if missing_ratio_current > 1e-9:
    unpaid_in_current_month += round(available_pool_upto_current * missing_ratio_current)

df_top3_final = pd.DataFrame(bonuses_rows)

# =========================
# KPIs (th√™m khu v·ª±c "C·∫≠p nh·∫≠t d·ªØ li·ªáu")
# =========================
kpi_num_seasons = df_current["leaderboard_id"].nunique()
kpi_num_users = df_current["user_id"].nunique()
total_lot_month = df_current["total_lot_standard"].max()
total_lot_month = 0 if pd.isna(total_lot_month) else total_lot_month

st.markdown("## KPIs T·ªïng quan")
col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
col1.metric("S·ªë Season (ƒëang xem)", kpi_num_seasons)
col2.metric("S·ªë User tham gia (th√°ng)", kpi_num_users)
col3.metric("T·ªïng Lot c·ªßa th√°ng", f"{total_lot_month:,.2f}")
col4.metric("Pool th√°ng hi·ªán t·∫°i (VNƒê)", f"{current_pool:,.0f}")
col5.metric("Pool s·∫µn c√≥ t·ªõi th√°ng n√†y (VNƒê)", f"{available_pool_upto_current:,.0f}")
col6.metric("Ti·ªÅn th∆∞·ªüng ƒë√£ chi trong th√°ng n√†y (VNƒê)", f"{bonus_given_from_available:,.0f}")
col7.metric("Ti·ªÅn ch∆∞a chi tr·∫£ TH√ÅNG N√ÄY (VNƒê)", f"{unpaid_in_current_month:,.0f}")

# --- Khu v·ª±c c·∫≠p nh·∫≠t d·ªØ li·ªáu ---
st.markdown("### ‚è±Ô∏è C·∫≠p nh·∫≠t d·ªØ li·ªáu")
u1, u2, u3 = st.columns(3)

def fmt_ts(ts):
    if ts is None or pd.isna(ts):
        return "‚Äî"
    # √©p v·ªÅ Asia/Ho_Chi_Minh ƒë·ªÉ hi·ªÉn th·ªã nh·∫•t qu√°n
    if pd.api.types.is_datetime64_any_dtype(pd.Series([ts])):
        # pandas Timestamp c√≥ tz ho·∫∑c kh√¥ng; chu·∫©n h√≥a:
        ts = pd.to_datetime(ts, utc=False)
    try:
        # N·∫øu ts l√† naive, coi nh∆∞ ƒë√£ c·ªông +7 ·ªü SQL ‚Üí g√°n tz cho VN
        ts = ts.tz_localize(ZoneInfo("Asia/Ho_Chi_Minh"))
    except Exception:
        # N·∫øu ƒë√£ c√≥ tz, convert sang VN
        ts = ts.tz_convert(ZoneInfo("Asia/Ho_Chi_Minh"))
    return ts.strftime("%Y-%m-%d %H:%M")

u1.metric("Order c·∫≠p nh·∫≠t ƒë·∫øn", fmt_ts(order_last_update))
u2.metric("PnL c·∫≠p nh·∫≠t ƒë·∫øn", fmt_ts(pnl_last_update))
u3.metric("Dashboard c·∫≠p nh·∫≠t l√∫c", now_local.strftime("%Y-%m-%d %H:%M"))

# B·∫£ng chi ti·∫øt 2 ngu·ªìn
if any(v is not None for v in [order_last_update, pnl_last_update]):
    st.dataframe(
        pd.DataFrame([
            {"Ngu·ªìn": "commodity.order", "C·∫≠p nh·∫≠t ƒë·∫øn (VN)": fmt_ts(order_last_update)},
            {"Ngu·ªìn": "pnl_close_status", "C·∫≠p nh·∫≠t ƒë·∫øn (VN)": fmt_ts(pnl_last_update)},
            {"Ngu·ªìn": "‚Üí Data update ƒë·∫øn (min)", "C·∫≠p nh·∫≠t ƒë·∫øn (VN)": fmt_ts(data_update_to)},
        ]),
        use_container_width=True, hide_index=True
    )

# =========================
# Top 3 th√°ng ƒëang ch·ªçn
# =========================
st.markdown("## üèÖ Top 3 User th√°ng hi·ªán t·∫°i")
st.dataframe(df_top3_final, use_container_width=True, hide_index=True)

# =========================
# Chi ti·∫øt c·ªông d·ªìn theo t·ª´ng th√°ng tr∆∞·ªõc
# =========================
with st.expander("Chi ti·∫øt c·ªông d·ªìn theo t·ª´ng th√°ng tr∆∞·ªõc"):
    if len(carryover_rows) == 0:
        st.info("Kh√¥ng c√≥ kho·∫£n c·ªông d·ªìn n√†o t·ª´ c√°c th√°ng tr∆∞·ªõc.")
    else:
        df_carry = pd.DataFrame(carryover_rows)
        display_cols = [
            "Season",
            "Pool th√°ng (VNƒê)",
            "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG TR∆Ø·ªöC (VNƒê)",
            "Pool s·∫µn c√≥ trong TH√ÅNG (VNƒê)",
            "ƒê√£ chi tr·∫£ trong TH√ÅNG (VNƒê)",
            "Ti·ªÅn ch∆∞a chi tr·∫£ trong TH√ÅNG (VNƒê)",
            "C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG (VNƒê)"
        ]
        st.dataframe(df_carry[display_cols], use_container_width=True, hide_index=True)
        st.caption(f"**C·ªông d·ªìn ch∆∞a chi ƒë·∫øn cu·ªëi TH√ÅNG TR∆Ø·ªöC:** {format_money(cumulative_unpaid_before)}")

# =========================
# B·∫£ng chi ti·∫øt t·∫•t c·∫£ User (th√°ng ƒëang ch·ªçn)
# =========================
st.markdown("## üìã B·∫£ng chi ti·∫øt t·∫•t c·∫£ User (th√°ng ƒëang ch·ªçn)")
for col in ["gross_pnl", "net_pnl", "transaction_fee"]:
    if col in df_current.columns:
        df_current[col] = pd.to_numeric(df_current[col], errors="coerce")

df_current["gross_pnl_fmt"] = df_current["gross_pnl"].apply(format_money) if "gross_pnl" in df_current.columns else "-"
df_current["net_pnl_fmt"] = df_current["net_pnl"].apply(format_money) if "net_pnl" in df_current.columns else "-"
df_current["transaction_fee_fmt"] = df_current["transaction_fee"].apply(format_money) if "transaction_fee" in df_current.columns else "-"

columns_to_show = [
    "leaderboard_id", "rank", "full_name", "user_id", "tkcv", "alias_name",
    "hidden_mode_activated_at", "mode", "registered_tnc_at", "lot", "lot_standard",
    "transaction_fee_fmt", "gross_pnl_fmt", "net_pnl_fmt"
]
available_cols = [c for c in columns_to_show if c in df_current.columns]
col_mapping = {
    "leaderboard_id": "Season",
    "rank": "H·∫°ng",
    "full_name": "T√™n",
    "user_id": "User ID",
    "tkcv": "T√†i kho·∫£n CV",
    "alias_name": "T√™n hi·ªÉn th·ªã",
    "hidden_mode_activated_at": "Ng√†y b·∫≠t ·∫©n danh",
    "mode": "Ch·∫ø ƒë·ªô",
    "registered_tnc_at": "Ng√†y ƒëƒÉng k√Ω",
    "transaction_fee_fmt": "Ph√≠ giao d·ªãch",
    "lot_standard": "Lot chu·∫©n",
    "lot": "Lot",
    "gross_pnl_fmt": "Gross PnL",
    "net_pnl_fmt": "Net PnL"
}
st.dataframe(
    df_current[available_cols].rename(columns=col_mapping),
    use_container_width=True,
    hide_index=True
)

# =========================
# Xu·∫•t CSV
# =========================
csv = df_current.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    label="T·∫£i d·ªØ li·ªáu CSV (th√°ng ƒëang ch·ªçn)",
    data=csv,
    file_name=f"advisory_user_ranks_{selected_season_name}.csv",
    mime="text/csv"
)
